<<<<<<< HEAD
geom_point(aes(x = rank_p, y = rank_d))+
geom_smooth(method = lm, mapping = aes(x = rank_p, y = rank_d),formula = y ~x, se = FALSE) %>%
ggtitle("Scatter Plot n/ Ranks for Total Population and Popluation Density")
ggplot(data = df_pop) +
geom_point(aes(x = rank_p, y = rank_d))+
geom_smooth(method = lm, mapping = aes(x = rank_p, y = rank_d),formula = y ~x, se = FALSE) +
ggtitle("Scatter Plot n/ Ranks for Total Population and Popluation Density")
summary(lm(rank_d ~ rank_p, data = df_pop))
ggplot(data = df_pop) +
geom_point(aes(x = rank_p, y = rank_d))+
geom_smooth(method = lm, mapping = aes(x = rank_p, y = rank_d),formula = y ~x, se = FALSE) +
ggtitle("Scatter Plot \n Ranks for Total Population and Popluation Density")
summary(lm(rank_d ~ rank_p, data = df_pop))
ggplot(data = df_pop) +
geom_point(aes(x = rank_p, y = rank_d))+
geom_smooth(method = lm, mapping = aes(x = rank_p, y = rank_d),formula = y ~x, se = FALSE) +
ggtitle("Ranks for Total Population and Popluation Density")
summary(lm(rank_d ~ rank_p, data = df_pop))
cor(df_pop$rank_p, df_pop$rank_d)
df_all %>%
left_join(df_pop, by = c("Country_Region" = "Location")) %>%
select(Population, PopTotal, everything())->df_allp
df_allp
df_allp02 %>%
ggplot(aes(x = current_totals, y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
scale_x_log10() +
ggtitle("The Number of Covid Confirmed cases for the Top 20 Country/Region")
df_pop
df_allp04 %>%
ggplot(aes(x = current_totals, y = total_percent))+
geom_point()+
scale_x_log10()+
scale_y_log10()+
geom_smooth(method = lm, formula = y ~ x, se = FALSE)+
ggtitle("Total Deaths versus Deaths per Popoulation")+
xlab("Deaths per Population(log)") +
ylab("Total Deaths(log)")
knitr::opts_chunk$set(fig.align  = "center",
fig.height = 5,
fig.width  = 6)
library(tidyverse)
library(broom)
url_in <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"
df <- tibble(file_names = c("time_series_covid19_confirmed_global.csv", "time_series_covid19_deaths_global.csv",
"time_series_covid19_confirmed_US.csv", "time_series_covid19_deaths_US.csv"))
df %>%
mutate(url = str_c(url_in, file_names, sep = ""))-> df
df
df %>%
mutate(data = map(url, ~read_csv(.)))->df
df
# Reference
# https://www.itread01.com/content/1548936390.html
# https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf
df %>%
mutate(case_type = as.factor(str_extract(file_names, "[a-z]*[:punct:][gU][a-zA-Z]*")))->df
df
df %>%
select(-file_names, -url)->df
df
df %>%
mutate(vars = map(data, names)) %>%
mutate(vars = map(vars, ~unlist(.)[1:15])) ->df
df
# Visually compare them
map(df$vars, ~unlist(.)[1:15])
# df$data
# df$vars
fix_names <- function(df, strP, repP){
stopifnot(is.data.frame(df), is.character(strP), is.character(repP))
names(df) <- str_replace_all(names(df), strP, repP)
return(df)
}
df %>%
mutate(data = map(data, ~fix_names(., "([ey])/", "\\1_")), # b
data = map(data, ~fix_names(., "Admin2", "County")), # c
data = map(data, ~fix_names(., "Long_", "Long")), # c
data = map_if(data, str_detect(df$case_type, "US"),
~select(., -c("UID", "iso2", "iso3", "code3", "FIPS", "Combined_Key"))), # d
data = map_if(data, str_detect(df$case_type,"global"), ~mutate(., Population = 0)),
data = map_if(data, str_detect(df$case_type, "global"), ~mutate(., County = "NA")),
data = map_if(data, str_detect(df$case_type, "confirmed_US"), ~mutate(., Population = 0)),# e
data = map(data, ~unite(., "Country_State", c("Country_Region", "Province_State"), sep = "_", remove = FALSE, na.rm = TRUE)),
data = map_if(data, str_detect(df$case_type, "global"), ~select(.,"Population", "County", everything())),
data = map_if(data, str_detect(df$case_type, "US"), ~select(.,"Population", "County", everything()))
) ->df #f
df
df %>%
mutate(vars = map(data, names)) %>%
mutate(vars = map(vars, ~unlist(.)[1:15])) ->df
df$vars
#df$data #---> check data
# reference:
# https://tidyr.tidyverse.org/articles/pivot.html
# https://dplyr.tidyverse.org/reference/select.html
library(lubridate)
df %>%
mutate(data = map(data, ~pivot_longer(data = ., cols = matches("\\/"), names_to = "Date", values_to = "daily_values", names_transform = list(Date = mdy))))->df_long
df_long
#df$data # ---> check data
# reference:
# https://github.com/vincentarelbundock/countrycode
# https://rdocumentation.org/packages/countrycode/versions/1.2.0/topics/countrycode
library(countrycode)
df_long %>%
mutate(data = map(data, ~mutate(., Continent = countrycode(Country_Region, "country.name", "continent"))))->df_long
#df$data
# information from wikipedia
# Diamond Princess ---> cruises operating in Asia
# Kosovo ---> Republika e Kosoves in Europe
# MS Zaandam ---> Cruises operating in Europe
# Micronesia ---> Federated States of Micronesia in Oceania
# df$data[[1]] %>% filter(Country_Region == "Diamond Princess") ---> check NA value
df_long %>%
mutate(data = map(data, ~mutate(., Continent = case_when(Country_Region == "Diamond Princess" ~ "Asia",
Country_Region == "Kosoves" ~ "Europe",
Country_Region == "MS Zaandam" ~ "Europe",
Country_Region == "Micronesia" ~"Oceania",
TRUE ~ Continent))))->df_long
map(df_long$data, ~unique(.$Continent))
df_long %>%
unnest(cols = data) %>%
ungroup()->df_all
df_all
# reference
# http://datasharkie.com/how-to-remove-data-frame-in-r
remove(df,df_long)
df_all %>%
select(-vars)->df_all
df_all
df_pop <- read_csv("./data/WPP2019_TotalPopulation.csv")
df_pop
setdiff(df_all$Country_Region, df_pop$Location)
setdiff(df_pop$Location, df_all$Country_Region) -> not_in_covid
not_in_covid
# 46 countries in there
df_pop %>%
filter(Location %in% not_in_covid) %>%
summarise(not_in_covid_total = sum(PopTotal)*1000)->sum_not_in_covid
df_pop %>%
summarise(world_pop = sum(PopTotal)*1000)->world_total_pop
sum_not_in_covid/world_total_pop
# Around 6 % of the world population contained in these countries
semi_join(df_pop, df_all, by = c("Location" = "Country_Region"))->df_pop
df_pop
# reference
# https://www.datasciencemadesimple.com/rank-function-in-r/
# https://stackoverflow.com/questions/26423493/r-rank-largest-to-smallest/26423543
df_pop %>%
mutate(rank_p = rank(-PopTotal, na.last = TRUE, ties.method = "min"),
rank_d = rank(-PopDensity, na.last = TRUE, ties.method = "min")) ->df_pop
df_pop %>%
arrange(rank_p) %>%
slice_head(n = 10) %>%
select(Location,PopTotal,rank_p)
df_pop %>%
arrange(rank_d) %>%
slice_head(n = 10) %>%
select(Location, PopDensity, rank_d)
ggplot(data = df_pop) +
geom_point(aes(x = rank_p, y = rank_d))+
geom_smooth(method = lm, mapping = aes(x = rank_p, y = rank_d),formula = y ~x, se = FALSE) +
ggtitle("Ranks for Total Population and Popluation Density")
cor(df_pop$rank_p, df_pop$rank_d)
summary(lm(rank_d ~ rank_p, data = df_pop))
df_all %>%
left_join(df_pop, by = c("Country_Region" = "Location")) %>%
select(Population, PopTotal, everything())->df_allp
df_allp
df_allp %>%
group_by(Country_Region) %>%
summarise(num_state = n_distinct(Country_State)) %>%
arrange(desc(num_state))
# 8 Country Regions have Multiple Country States
df_allp %>%
group_by(Country_Region, Continent, case_type, rank_p, rank_d) %>%
summarise(current_totals = max(daily_values),
total_percent = current_totals/ (last(PopTotal)*1000)*100) -> df_allp01
df_allp01
df_allp01 %>%
ungroup() %>%
filter(case_type == "confirmed_global") %>%
arrange(desc(current_totals)) %>%
slice_head(n = 20)->df_allp02
df_allp02
#sum(df_allp02$current_totals)/world_total_pop*100
df_allp01 %>%
ungroup() %>%
filter(case_type == "deaths_global") %>%
arrange(desc(current_totals)) %>%
slice_head(n = 20)->df_allp03
df_allp03
df_pop
df_allp01 %>%
ungroup() %>%
filter(case_type == "confirmed_global") %>%
arrange(desc(total_percent)) %>%
slice_head(n = 20)->df_allp04
setdiff(df_allp04, df_allp02)
df_allp01 %>%
ungroup() %>%
filter(case_type == "deaths_global") %>%
arrange(desc(total_percent)) %>%
slice_head(n = 20)->df_allp05
setdiff(df_allp05, df_allp03)
df_allp02 %>%
ggplot(aes(x = current_totals, y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
scale_x_log10() +
ggtitle("The Number of Covid Confirmed cases for the Top 20 Country/Region")
df_allp03 %>%
ggplot(aes(x = current_totals, y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
scale_x_log10()+
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
df_allp %>%
group_by(Country_State, case_type) %>%
summarise(current_totals = max(daily_values),
total_percent = current_totals/(last(PopTotal)*1000)*100) %>%
filter(case_type == "deaths_US", current_totals > 0) ->df_allp04
df_allp04
df_allp04 %>%
ggplot(aes(x = current_totals, y = total_percent))+
geom_point()+
scale_x_log10()+
scale_y_log10()+
geom_smooth(method = lm, formula = y ~ x, se = FALSE)+
ggtitle("Total Deaths versus Deaths per Popoulation")+
xlab("Deaths per Population(log)") +
ylab("Total Deaths(log)")
augmented_reg <- augment(augmented_reg)
aug_reg <- augment(aug_reg)
reg <- lm(total_percent ~ current_totals, data = df_allp04)
aug_reg <- augment(reg)
ggplot(aug_reg, aes( x = .fitted, y = .resid))+
geom_point()
df_allp03 %>%
ggplot(aes(x = log10(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
scale_x_log10()+
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
df_allp03 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
scale_x_log10()+
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
df_allp03 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
#scale_x_log10()+
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
df_allp02 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
ggtitle("The Number of Covid Confirmed cases for the Top 20 Country/Region")
df_allp03 %>%
ggplot(aes(x = log10(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
df_allp03 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
knitr::opts_chunk$set(fig.align  = "center",
fig.height = 5,
fig.width  = 6)
library(tidyverse)
library(broom)
url_in <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"
df <- tibble(file_names = c("time_series_covid19_confirmed_global.csv", "time_series_covid19_deaths_global.csv",
"time_series_covid19_confirmed_US.csv", "time_series_covid19_deaths_US.csv"))
df %>%
mutate(url = str_c(url_in, file_names, sep = ""))-> df
df
df %>%
mutate(data = map(url, ~read_csv(.)))->df
df
# Reference
# https://www.itread01.com/content/1548936390.html
# https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf
df %>%
mutate(case_type = as.factor(str_extract(file_names, "[a-z]*[:punct:][gU][a-zA-Z]*")))->df
df
df %>%
select(-file_names, -url)->df
df
df %>%
mutate(vars = map(data, names)) %>%
mutate(vars = map(vars, ~unlist(.)[1:15])) ->df
df
# Visually compare them
map(df$vars, ~unlist(.)[1:15])
# df$data
# df$vars
fix_names <- function(df, strP, repP){
stopifnot(is.data.frame(df), is.character(strP), is.character(repP))
names(df) <- str_replace_all(names(df), strP, repP)
return(df)
}
df %>%
mutate(data = map(data, ~fix_names(., "([ey])/", "\\1_")), # b
data = map(data, ~fix_names(., "Admin2", "County")), # c
data = map(data, ~fix_names(., "Long_", "Long")), # c
data = map_if(data, str_detect(df$case_type, "US"),
~select(., -c("UID", "iso2", "iso3", "code3", "FIPS", "Combined_Key"))), # d
data = map_if(data, str_detect(df$case_type,"global"), ~mutate(., Population = 0)),
data = map_if(data, str_detect(df$case_type, "global"), ~mutate(., County = "NA")),
data = map_if(data, str_detect(df$case_type, "confirmed_US"), ~mutate(., Population = 0)),# e
data = map(data, ~unite(., "Country_State", c("Country_Region", "Province_State"), sep = "_", remove = FALSE, na.rm = TRUE)),
data = map_if(data, str_detect(df$case_type, "global"), ~select(.,"Population", "County", everything())),
data = map_if(data, str_detect(df$case_type, "US"), ~select(.,"Population", "County", everything()))
) ->df #f
df
df %>%
mutate(vars = map(data, names)) %>%
mutate(vars = map(vars, ~unlist(.)[1:15])) ->df
df$vars
#df$data #---> check data
# reference:
# https://tidyr.tidyverse.org/articles/pivot.html
# https://dplyr.tidyverse.org/reference/select.html
library(lubridate)
df %>%
mutate(data = map(data, ~pivot_longer(data = ., cols = matches("\\/"), names_to = "Date", values_to = "daily_values", names_transform = list(Date = mdy))))->df_long
df_long
#df$data # ---> check data
# reference:
# https://github.com/vincentarelbundock/countrycode
# https://rdocumentation.org/packages/countrycode/versions/1.2.0/topics/countrycode
library(countrycode)
df_long %>%
mutate(data = map(data, ~mutate(., Continent = countrycode(Country_Region, "country.name", "continent"))))->df_long
#df$data
# information from wikipedia
# Diamond Princess ---> cruises operating in Asia
# Kosovo ---> Republika e Kosoves in Europe
# MS Zaandam ---> Cruises operating in Europe
# Micronesia ---> Federated States of Micronesia in Oceania
# df$data[[1]] %>% filter(Country_Region == "Diamond Princess") ---> check NA value
df_long %>%
mutate(data = map(data, ~mutate(., Continent = case_when(Country_Region == "Diamond Princess" ~ "Asia",
Country_Region == "Kosoves" ~ "Europe",
Country_Region == "MS Zaandam" ~ "Europe",
Country_Region == "Micronesia" ~"Oceania",
TRUE ~ Continent))))->df_long
map(df_long$data, ~unique(.$Continent))
df_long %>%
unnest(cols = data) %>%
ungroup()->df_all
df_all
# reference
# http://datasharkie.com/how-to-remove-data-frame-in-r
remove(df,df_long)
df_all %>%
select(-vars)->df_all
df_all
df_pop <- read_csv("./data/WPP2019_TotalPopulation.csv")
df_pop
setdiff(df_all$Country_Region, df_pop$Location)
setdiff(df_pop$Location, df_all$Country_Region) -> not_in_covid
not_in_covid
# 46 countries in there
df_pop %>%
filter(Location %in% not_in_covid) %>%
summarise(not_in_covid_total = sum(PopTotal)*1000)->sum_not_in_covid
df_pop %>%
summarise(world_pop = sum(PopTotal)*1000)->world_total_pop
sum_not_in_covid/world_total_pop
# Around 6 % of the world population contained in these countries
semi_join(df_pop, df_all, by = c("Location" = "Country_Region"))->df_pop
df_pop
# reference
# https://www.datasciencemadesimple.com/rank-function-in-r/
# https://stackoverflow.com/questions/26423493/r-rank-largest-to-smallest/26423543
df_pop %>%
mutate(rank_p = rank(-PopTotal, na.last = TRUE, ties.method = "min"),
rank_d = rank(-PopDensity, na.last = TRUE, ties.method = "min")) ->df_pop
df_pop %>%
arrange(rank_p) %>%
slice_head(n = 10) %>%
select(Location,PopTotal,rank_p)
df_pop %>%
arrange(rank_d) %>%
slice_head(n = 10) %>%
select(Location, PopDensity, rank_d)
ggplot(data = df_pop) +
geom_point(aes(x = rank_p, y = rank_d))+
geom_smooth(method = lm, mapping = aes(x = rank_p, y = rank_d),formula = y ~x, se = FALSE) +
ggtitle("Ranks for Total Population and Popluation Density")
cor(df_pop$rank_p, df_pop$rank_d)
summary(lm(rank_d ~ rank_p, data = df_pop))
df_all %>%
left_join(df_pop, by = c("Country_Region" = "Location")) %>%
select(Population, PopTotal, everything())->df_allp
df_allp
df_allp %>%
group_by(Country_Region) %>%
summarise(num_state = n_distinct(Country_State)) %>%
arrange(desc(num_state))
# 8 Country Regions have Multiple Country States
df_allp %>%
group_by(Country_Region, Continent, case_type, rank_p, rank_d) %>%
summarise(current_totals = max(daily_values),
total_percent = current_totals/ (last(PopTotal)*1000)*100) -> df_allp01
df_allp01
df_allp01 %>%
ungroup() %>%
filter(case_type == "confirmed_global") %>%
arrange(desc(current_totals)) %>%
slice_head(n = 20)->df_allp02
df_allp02
#sum(df_allp02$current_totals)/world_total_pop*100
df_allp01 %>%
ungroup() %>%
filter(case_type == "deaths_global") %>%
arrange(desc(current_totals)) %>%
slice_head(n = 20)->df_allp03
df_allp03
df_allp01 %>%
ungroup() %>%
filter(case_type == "confirmed_global") %>%
arrange(desc(total_percent)) %>%
slice_head(n = 20)->df_allp04
setdiff(df_allp04, df_allp02)
df_allp01 %>%
ungroup() %>%
filter(case_type == "deaths_global") %>%
arrange(desc(total_percent)) %>%
slice_head(n = 20)->df_allp05
setdiff(df_allp05, df_allp03)
df_allp02 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
ggtitle("The Number of Covid Confirmed cases for the Top 20 Country/Region")
df_allp03 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
df_allp %>%
group_by(Country_State, case_type) %>%
summarise(current_totals = max(daily_values),
total_percent = current_totals/(last(PopTotal)*1000)*100) %>%
filter(case_type == "deaths_US", current_totals > 0) ->df_allp04
df_allp04
df_allp04 %>%
ggplot(aes(x = current_totals, y = total_percent))+
geom_point()+
scale_x_log10()+
scale_y_log10()+
geom_smooth(method = lm, formula = y ~ x, se = FALSE)+
ggtitle("Total Deaths versus Deaths per Popoulation")+
xlab("Deaths per Population(log)") +
ylab("Total Deaths(log)")
knitr::opts_chunk$set(fig.align  = "center",
fig.height = 5,
fig.width  = 6)
df_allp02 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
ggtitle("The Number of Covid Confirmed cases for the Top 20 Country/Region")
df_allp03 %>%
ggplot(aes(x = log(current_totals), y = Country_Region)) +
geom_col() +
facet_grid(Continent ~ .) +
ggtitle("The Number of Covid Deaths cases for the Top 20 Country/Region")
df_allp04 %>%
ggplot(aes(x = current_totals, y = total_percent))+
geom_point()+
scale_x_log10()+
scale_y_log10()+
geom_smooth(method = lm, formula = y ~ x, se = FALSE)+
ggtitle("Total Deaths versus Deaths per Popoulation")+
xlab("Deaths per Population(log)") +
ylab("Total Deaths(log)")
df_allp01 %>%
ungroup() %>%
filter(case_type == "confirmed_global") %>%
arrange(desc(current_totals)) %>%
slice_head(n = 20)->df_allp02
df_allp02
df_allp %>%
group_by(Country_Region, Continent, case_type, rank_p, rank_d) %>%
summarise(current_totals = max(daily_values),
total_percent = current_totals/ (last(PopTotal)*1000)*100) -> df_allp01
df_allp01
df_allp01 %>%
ungroup() %>%
filter(case_type == "confirmed_global") %>%
arrange(desc(current_totals)) %>%
slice_head(n = 20)->df_allp02
df_allp02
library(tidyverse)
library(leaps)
library(car)
library(MASS)
covid_df <- read_csv("../data/covid_df_regression.csv")
covid_df %>%
select(-Province_State, -Total_Population) -> covid_df
setwd("~/CYL/fp_final-project-group-5/DS_Final_App")
=======
# positive
books_bing_count %>%
filter(sentiment == "positive") %>%
group_by(book) %>%
slice_max(order_by = n, n = 10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = n, y = word)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, scales = "free_y") +
labs(x = "Contribution to Book", y = NULL)
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
filter(sentiment == "positive")
# positive
books_bing_count %>%
group_by(book, sentiment) %>%
slice_max(order_by = n, n=10) %>%
ungroup() %>%
mutate(word = reorder_within(word, n, book)) %>%
ungroup() %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(sentiment ~book, scales = "free") +
scale_x_reordered() +
scale_y_continuous(expand = c(0,0)) +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
get_sentiments("bing") %>%
filter(word != "miss") ->
bing_no_miss
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
group_by(book, word, sentiment) %>%
count() ->
books_bing_nomiss
books_bing_nomiss %>%
group_by(book, sentiment) %>%
slice_max(order_by = n, n=10) %>%
ungroup() %>%
mutate(word = reorder_within(word, n, book)) %>%
ungroup() %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(sentiment ~book, scales = "free") +
scale_x_reordered() +
scale_y_continuous(expand = c(0,0)) +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
# filter out miss
get_sentiments("bing") %>%
filter(word != "miss") ->
bing_no_miss
# no miss df
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
group_by(book, word, sentiment) %>%
count() ->
books_bing_nomiss
books_bing_nomiss %>%
group_by(book, sentiment) %>%
slice_max(order_by = n, n=10) %>%
ungroup() %>%
mutate(word = reorder_within(word, n, book)) %>%
ungroup() %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(sentiment ~book, scales = "free") +
scale_x_reordered() +
scale_y_continuous(expand = c(0,0)) +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
books_bing_count %>%
group_by(book, sentiment) %>%
slice_max(order_by = n, n = 10) %>%
ungroup() %>%
mutate(word = reorder_within(word, n, book)) %>%
ungroup() %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(sentiment ~book, scales = "free") +
scale_x_reordered() +
scale_y_continuous(expand = c(0,0)) +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
# "miss" may be inappropriate for the context of the book
# filter out miss
get_sentiments("bing") %>%
filter(word != "miss") ->
bing_no_miss
# no miss df
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
group_by(book, word, sentiment) %>%
count() ->
books_bing_nomiss
books_bing_nomiss %>%
group_by(book, sentiment) %>%
slice_max(order_by = n, n = 10) %>%
ungroup() %>%
mutate(word = reorder_within(word, n, book)) %>%
ungroup() %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(sentiment ~book, scales = "free") +
scale_x_reordered() +
scale_y_continuous(expand = c(0,0)) +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
# Interpretation:
# step5
twobooks_tidy %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
books_bing_plot
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
books_bing_plot
# step5
twobooks_tidy %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
books_bing_plot
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
books_bing_plot_nomiss
# step5
twobooks_tidy %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
books_bing_plot
books_bing_plot
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
books_bing_plot_nomiss
books_bing_plot_nomiss
# from step5
twobooks_tidy %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
p1
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
p2
library(gridExtra)
grid.arrange(p1, p2, nrow=2)
# from step5
twobooks_tidy %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
ggtitle("With Miss as Negative" ) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
p1
twobooks_tidy %>%
inner_join(bing_no_miss, by = "word") %>%
count(book, index = linenumber %/% 50, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
ggtitle("Without Miss as Negative" ) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x") ->
p2
library(gridExtra)
grid.arrange(p1, p2, nrow=2)
# Interpretation:
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
filter(sentiment == "negative") %>%
count(book, index = linenumber %/% 500, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
filter(sentiment == "negative" & sentiment == "positive") %>%
count(book, index = linenumber %/% 500, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
filter(sentiment == "negative" | sentiment == "positive") %>%
count(book, index = linenumber %/% 500, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
filter(sentiment == "negative" | sentiment == "positive")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
filter(sentiment == "negative" | sentiment == "positive") %>%
count(book, index = linenumber %/% 500, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
filter(sentiment == "negative" | sentiment == "positive") %>%
count(book, index = linenumber %/% 50, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
filter(sentiment == "negative" | sentiment == "positive") %>%
count(book, index = linenumber %/% 500, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(sentiment == "negative" | sentiment == "positive")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive"))
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
mutate(net = positive - negative) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0))
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
ggplot(aes(index, net, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive"))
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
ggplot(aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE)
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
# pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
ggplot(aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
# pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
ggplot(aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(sentiment~book, ncol = 2, scales = "free_x")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
# pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
ggplot(aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive"))
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0))
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
# pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
group_by(sentiment) %>%
count()
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
# pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
group_by(book, sentiment) %>%
count()
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
# pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
group_by(book, sentiment, index) %>%
count()
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
# pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n=0)) %>%
group_by(book, sentiment, index) %>%
count() %>%
ungroup() %>%
ggplot(aes(index, n, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(sentiment~book, ncol = 2, scales = "free_x")
twobooks_tidy %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(book, index = linenumber %/% 500, sentiment) %>%
filter(!(sentiment == "negative" | sentiment == "positive"))
meta_fields
gutenberg_works() %>%
filter(str_detect(author, "Mark Twain"))
gutenberg_works() %>%
filter(str_detect(author, "Twain"))
gutenberg_works() %>%
filter(str_detect(title, "Huckleberry Finn"))
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer")))
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad")))
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) %>%
selet(gutenberg_id)
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) %>%
select(gutenberg_id)
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) %>%
select(gutenberg_id) %>%
as.character()
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) %>%
select(gutenberg_id) %>%
as.character() ->
marksbook
gutenberg_download(marksbook)
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) %>%
select(gutenberg_id)
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad")))
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) ->
mtsbook
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) ->
mtsbook
mtsid <- mtsbook$gutenberg_id
gutenberg_download(mtsid)
gutenberg_download(mtsid, meta_fields = author)
gutenberg_download(mtsid, meta_fields = "author")
mtsbooks_df <- gutenberg_download(mtsid, meta_fields = "author")
gutenberg_works() %>%
filter(str_detect(title, c("Huckleberry Finn", "Tom Sawyer", "Connecticut Yankee in King Arthur's Court", "Life on the Mississippi", "Prince and the Pauper", "A Tramp Abroad"))) ->
mtsbook
mtsid <- mtsbook$gutenberg_id # store ids
mtsbooks_df <- gutenberg_download(mtsid, meta_fields = "author") # download the books
View(mtsbooks_df)
to_tfidf <- function(x){
x %>%
mutate(linenumber = row_number(),               # add line and chapter numbers as variables
chapter = cumsum(str_detect(text,
regex("^chapter [ivxlc]",
ignore_case = TRUE)))) %>%
unnest_tokens(word, text) %>%                   # unnest tokens at the word level
mutate(word = str_extract(word, "[a-z']+")) %>% # only the words remain
filter(chapter != 0) %>%                        # remove any front matter
count(book, word, sort = TRUE) ->
y
y %>%
group_by(book) %>%
summarize(total = sum(n), .groups = "keep") ->
total_words
y %>%
left_join(total_words, by = "book") ->
y
y
}
to_tfidf(mtsbooks_df)
mtsbooks_df %>%
mutate(linenumber = row_number(),               # add line and chapter numbers as variables
chapter = cumsum(str_detect(text,
regex("^chapter [ivxlc]",
ignore_case = TRUE)))) %>%
unnest_tokens(word, text) %>%                   # unnest tokens at the word level
mutate(word = str_extract(word, "[a-z']+")) %>% # only the words remain
filter(chapter != 0) %>%                        # remove any front matter
count(word, sort = TRUE)
mtsbooks_df %>%
mutate(linenumber = row_number(),               # add line and chapter numbers as variables
chapter = cumsum(str_detect(text,
regex("^chapter [ivxlc]",
ignore_case = TRUE)))) %>%
unnest_tokens(word, text) %>%                   # unnest tokens at the word level
mutate(word = str_extract(word, "[a-z']+")) %>% # only the words remain
filter(chapter != 0) %>%                        # remove any front matter
count(title, word, sort = TRUE)
knitr::opts_chunk$set(echo = TRUE)
covid_data <- read.csv("../../DS_final_data/COVID-19_Case.csv")
covid_data <- read.csv("~/Desktop/STAT613/Data Science Project/covid_data.csv")
covid_data <- read.csv("../DS_final_data/COVID-19_Case.csv")
# Remove all rows with NA values in the race column
covid_data <- covid_data[!is.na(covid_data$race), ]
# Remove all rows containing "Missing" values in the race column
covid_data <- covid_data[-grep("Missing", covid_data$race), ]
# Remove all rows containing "Unknown" values in the race column
covid_data <- covid_data[-grep("Unknown", covid_data$race), ]
View(covid_data)
covid_data <- read.csv("../DS_final_data/COVID-19_Case.csv")
# Remove all rows with NA values in the race column
covid_data <- covid_data[!is.na(covid_data$race), ]
# Remove all rows containing "Missing" values in the race column
covid_data <- covid_data[-grep("Missing", covid_data$race), ]
# Remove all rows containing "Unknown" values in the race column
covid_data <- covid_data[-grep("Unknown", covid_data$race), ]
covid %>%
saveRDS(../Data/tidy_covid19_case.rds)
covid_data %>%
saveRDS(../Data/tidy_covid19_case.rds)
covid_data %>%
saveRDS("../Data/tidy_covid19_case.rds")
covid_data %>%
saveRDS("/Data/tidy_covid19_case.rds")
covid_data %>%
saveRDS("Data/tidy_covid19_case.rds")
View(covid_data)
covid_data %>%
select(-case_positive_specimen_interval, -case_onset_interval) ->
covid_data
View(covid_data)
covid_data %>%
select(-case_positive_specimen_interval, -case_onset_interval, -exposure_yn) ->
covid_data
covid_data %>%
select(-exposure_yn) ->
covid_data
covid_data %>%
saveRDS("Data/tidy_covid19_case.rds")
library(readr)
library(tidyverse)
library(ggplot2)
readr::readRDS("../Data/tidy_covid19_case.rds") ->
covid19_data
readRDS("../Data/tidy_covid19_case.rds") ->
covid19_data
readRDS("../Data/tidy_covid19_case.rds") ->
covid19_data
setwd("~/Documents/Stat_613_DS/DS_final_project/DS_Final_App")
shiny::runApp()
readr::read_rds("data/covid19_tidy.rds") ->
covid19_tidy
View(covid19_tidy)
covid19_tidy %>%
filter(case_month == "2020-01-01")
covid19_tidy %>%
filter(case_month == "2020-12-01")
runApp()
>>>>>>> main
